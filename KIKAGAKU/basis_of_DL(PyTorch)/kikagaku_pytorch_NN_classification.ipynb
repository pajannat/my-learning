{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの実装（分類）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Lightning による学習ループの簡略化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from pytorch_lightning) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from pytorch_lightning) (1.23.1)\n",
      "Collecting PyYAML>=5.4\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting lightning-utilities>=0.4.2\n",
      "  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from pytorch_lightning) (1.13.1)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.4)\n",
      "Requirement already satisfied: requests; extra == \"http\" in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\" in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from requests; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from requests; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from requests; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from requests; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (2020.6.20)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\n",
      "Installing collected packages: typing-extensions, torchmetrics, PyYAML, lightning-utilities, tqdm, fsspec, pytorch-lightning\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインストール\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Using cached pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting packaging>=17.1\n",
      "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Using cached fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "Collecting numpy>=1.17.2\n",
      "  Using cached numpy-1.24.1-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting torch>=1.10.0\n",
      "  Using cached torch-1.13.1-cp38-cp38-win_amd64.whl (162.6 MB)\n",
      "Collecting lightning-utilities>=0.4.2\n",
      "  Using cached lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
      "Collecting colorama; platform_system == \"Windows\"\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"\n",
      "  Using cached aiohttp-3.8.3-cp38-cp38-win_amd64.whl (324 kB)\n",
      "Collecting requests; extra == \"http\"\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp38-cp38-win_amd64.whl (56 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Installing collected packages: colorama, tqdm, packaging, frozenlist, idna, multidict, yarl, charset-normalizer, attrs, async-timeout, aiosignal, aiohttp, urllib3, certifi, requests, fsspec, numpy, typing-extensions, torch, PyYAML, lightning-utilities, torchmetrics, pytorch-lightning\n",
      "Successfully installed PyYAML-6.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 attrs-22.2.0 certifi-2022.12.7 charset-normalizer-2.1.1 colorama-0.4.6 frozenlist-1.3.3 fsspec-2023.1.0 idna-3.4 lightning-utilities-0.5.0 multidict-6.0.4 numpy-1.24.1 packaging-23.0 pytorch-lightning-1.9.0 requests-2.28.2 torch-1.13.1 torchmetrics-0.11.0 tqdm-4.64.1 typing-extensions-4.4.0 urllib3-1.26.14 yarl-1.8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "scipy 1.7.0 requires numpy<1.23.0,>=1.16.5, but you'll have numpy 1.24.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning --ignore-installed PyYAML --user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み（df: data frame）\n",
    "df = pd.read_csv('./data/wine_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0      1    14.23  2.43               15.6        127           2.80   \n",
       "1      1    13.20  2.14               11.2        100           2.65   \n",
       "2      1    13.16  2.67               18.6        101           2.80   \n",
       "3      1    14.37  2.50               16.8        113           3.85   \n",
       "4      1    13.24  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Color intensity   Hue  Proline  \n",
       "0        3.06                  0.28             5.64  1.04     1065  \n",
       "1        2.76                  0.26             4.38  1.05     1050  \n",
       "2        3.24                  0.30             5.68  1.03     1185  \n",
       "3        3.49                  0.24             7.80  0.86     1480  \n",
       "4        2.69                  0.39             4.32  1.04      735  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの表示（先頭の5件）\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力変数と目的変数に切り分け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3], dtype=int64), array([59, 71, 48], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['Class'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class', axis=1)\n",
    "t = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol   Ash  Alcalinity of ash  Magnesium  Total phenols  Flavanoids  \\\n",
       "0    14.23  2.43               15.6        127           2.80        3.06   \n",
       "1    13.20  2.14               11.2        100           2.65        2.76   \n",
       "2    13.16  2.67               18.6        101           2.80        3.24   \n",
       "\n",
       "   Nonflavanoid phenols  Color intensity   Hue  Proline  \n",
       "0                  0.28             5.64  1.04     1065  \n",
       "1                  0.26             4.38  1.05     1050  \n",
       "2                  0.30             5.68  1.03     1185  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 表示して確認\n",
    "x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 10), (178,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズの確認\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pandas.core.series.Series)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), type(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.core.frame.DataFrame、 pandas.core.series.Series 型から \n",
    "# Tensor 型への直接変換ができないため、一度 NumPy の形式に変換\n",
    "# NumPy の形式に変換するには、.values を使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor 形式へ変換\n",
    "x = torch.tensor(x.values, dtype=torch.float32)\n",
    "t = torch.tensor(t.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分類の場合にはラベルが 0 から始まらなければならない\n",
    "# 1, 2, 3 → 0, 1, 2 と変換\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベルを 0 から始める\n",
    "t = t - 1 \n",
    "t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset にまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x2194e40e910>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch では x と t をひとつにまとめることが一般的\n",
    "# TensorDataset を使う\n",
    "\n",
    "# 入力変数と目的変数をまとめて、ひとつのオブジェクト dataset に変換\n",
    "dataset = torch.utils.data.TensorDataset(x, t)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4230e+01, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00, 3.0600e+00,\n",
       "         2.8000e-01, 5.6400e+00, 1.0400e+00, 1.0650e+03]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (入力変数, 目的変数) のようにタプルで格納されている\n",
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用データ、検証用データ、テスト用データに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前章では設定した DataLoader の設定は \n",
    "# PyTorch Lightning 側で用意されているため必要なし\n",
    "# こちらでは、学習用、検証用、テスト用のデータセットの分割だけ行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データセットのサンプル数を決定\n",
    "# train : val : test = 60% : 20% : 20%\n",
    "n_train = int(len(dataset) * 0.6)\n",
    "n_val = int((len(dataset) - n_train) * 0.5)\n",
    "n_test = len(dataset) - n_train - n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 36, 36)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サンプル数の確認\n",
    "n_train, n_val, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Lightning によるモデルと学習手順の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを定義する際のクラスは nn.Module を継承していたが、\n",
    "# この点を PyTorch Lightning の LightningModule を継承\n",
    "# まずは検証データとテストデータを抜いた学習データのみに対する最小限のクラスを設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バージョンの確認\n",
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    # nn -> pl: バッチサイズ等を引数に指定する\n",
    "    def __init__(self, input_size=10, hidden_size=5, output_size=3, batch_size=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # nn -> pl: 変更なし\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    # nn -> pl: 目的関数の設定\n",
    "    def lossfun(self, y, t):\n",
    "        return F.cross_entropy(y, t)\n",
    "    \n",
    "    # nn -> pl: optimizer の設定\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "\n",
    "    # nn -> pl: train 用の DataLoader の設定\n",
    "    # @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(train, self.batch_size, shuffle=True)\n",
    "\n",
    "    # nn -> pl: 学習データに対する処理\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        results = {'loss': loss}\n",
    "        return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシード固定\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# インスタンス化\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# 学習用に用いるクラスの Trainer をインスタンス化\n",
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\loops\\utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: c:\\Users\\ytchi\\Development\\Python\\work\\lightning_logs\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc1  | Linear | 55    \n",
      "1 | fc2  | Linear | 18    \n",
      "--------------------------------\n",
      "73        Trainable params\n",
      "0         Non-trainable params\n",
      "73        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "c:\\Users\\ytchi\\anaconda3\\envs\\py37\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|█████████ | 10/11 [00:00<00:00, 65.03it/s, loss=4.47, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1600: PossibleUserWarning: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 11/11 [00:00<00:00, 75.16it/s, loss=1.1, v_num=0]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 11/11 [00:00<00:00, 67.15it/s, loss=1.1, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "# Trainer によるモデルの学習\n",
    "trainer.fit(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer の引数の中でも代表的なものを紹介しておきます。\n",
    "\n",
    "# 引数名                  デフォルトの値    説明\n",
    "# show_progress_bar\t    True            学習時の進捗を標準出力\n",
    "# max_epochs\t            1000            学習時の最大エポック数\n",
    "# min_epochs\t            1               学習時の最小エポック数\n",
    "# train_percent_check\t    1.0             学習データに対する確認の比率 (%)\n",
    "# val_percent_check\t    1.0             検証データに対する確認の比率 (%)\n",
    "# test_percent_check\t    1.0             テストデータに対する確認の比率 (%)\n",
    "# early_stop_callback\t    False           早期終了の使用の有無\n",
    "# gpus\t                None            使用するGPUの数\n",
    "# distributed_backend\t    None            分散学習の方法\n",
    "# 抑えておくべき点として、デフォルトでは early_stop_callback=False であるため、\n",
    "# 早期終了 (early stopping) が適用されていない。\n",
    "# 早期終了とはある計測する指標に対して学習によって変化がなくなった場合に終了する方法。\n",
    "# 基本的には、検証データに対する目的関数の値もしくは正解率などが指標として採用される。\n",
    "# そのため、エポックの数は max_nb_epochs で最大の数を指定する程度で、\n",
    "# あとは早期終了を有効にし、不要な学習は打ち切ることにすることも多い。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証データの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_step は検証データに対する各イテレーションごとの結果\n",
    "# validation_end はエポック毎にその結果を集計\n",
    "# 検証データやテストデータに対する計算の場合には、\n",
    "# torch.no_grad() を用いて勾配情報を持たないようにしていたが、\n",
    "# そういった処理も PyTorch Lightning 側で設定されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    # nn -> pl: バッチサイズ等を引数に指定する\n",
    "    def __init__(self, input_size=10, hidden_size=5, output_size=3, batch_size=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # nn -> pl: 変更なし\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    # nn -> pl: 目的関数の設定\n",
    "    def lossfun(self, y, t):\n",
    "        return F.cross_entropy(y, t)\n",
    "    \n",
    "    # nn -> pl: optimizer の設定\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "\n",
    "    # nn -> pl: train 用の DataLoader の設定\n",
    "    # @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(train, self.batch_size, shuffle=True)\n",
    "\n",
    "    # nn -> pl: 学習データに対する処理\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        results = {'loss': loss}\n",
    "        return results\n",
    "\n",
    "    # nn -> pl: 検証用データセットの設定\n",
    "    # @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(val, self.batch_size)\n",
    "    \n",
    "    # nn -> pl: 検証データに対するイテレーションごとの処理\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        \n",
    "        # 正解率の算出\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        acc = torch.sum(t == y_label) * 1.0 / len(t)\n",
    "        results = {'val_loss': loss, 'val_acc': acc}\n",
    "        return results\n",
    "    \n",
    "    # nn -> pl: 検証データに対するエポックごとの処理\n",
    "    def validation_end(self, outputs):\n",
    "        # 各イテレーションごとに得られた値をまとめて、平均値の取得\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc  =torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        results = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = Net()\n",
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory c:\\Users\\ytchi\\Development\\Python\\work\\lightning_logs\\version_1\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc1  | Linear | 55    \n",
      "1 | fc2  | Linear | 18    \n",
      "--------------------------------\n",
      "73        Trainable params\n",
      "0         Non-trainable params\n",
      "73        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138:  73%|███████▎  | 11/15 [00:00<00:00, 82.00it/s, loss=1.1, v_num=1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1600: PossibleUserWarning: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 90.68it/s, loss=1.09, v_num=1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 85.91it/s, loss=1.09, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "trainer.fit(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データと同様に、テストデータに対する結果が得られるようにクラスにメソッドを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    # nn -> pl: バッチサイズ等を引数に指定する\n",
    "    def __init__(self, input_size=10, hidden_size=5, output_size=3, batch_size=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # nn -> pl: 変更なし\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    # nn -> pl: 目的関数の設定\n",
    "    def lossfun(self, y, t):\n",
    "        return F.cross_entropy(y, t)\n",
    "    \n",
    "    # nn -> pl: optimizer の設定\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "\n",
    "    # nn -> pl: train 用の DataLoader の設定\n",
    "    # @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(train, self.batch_size, shuffle=True)\n",
    "\n",
    "    # nn -> pl: 学習データに対する処理\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        results = {'loss': loss}\n",
    "        return results\n",
    "\n",
    "    # nn -> pl: 検証用データセットの設定\n",
    "    # @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(val, self.batch_size)\n",
    "    \n",
    "    # nn -> pl: 検証データに対するイテレーションごとの処理\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        \n",
    "        # 正解率の算出\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        acc = torch.sum(t == y_label) * 1.0 / len(t)\n",
    "        results = {'val_loss': loss, 'val_acc': acc}\n",
    "        return results\n",
    "    \n",
    "    # nn -> pl: 検証データに対するエポックごとの処理\n",
    "    def validation_end(self, outputs):\n",
    "        # 各イテレーションごとに得られた値をまとめて、平均値の取得\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc  =torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        results = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        return results\n",
    "\n",
    "    # nn -> pl: テストデータセットの設定\n",
    "    # @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(test, self.batch_size)\n",
    "    \n",
    "    # nn -> pl: テストデータに対するイテレーションごとの処理\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        acc = torch.sum(t == y_label) * 1.0 / len(t)\n",
    "        results = {'test_loss': loss, 'test_acc': acc}\n",
    "        return results\n",
    "    \n",
    "    # nn -> pl: テストデータに対するエポックごとの処理\n",
    "    def test_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        results = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\ytchi\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\loops\\utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc1  | Linear | 55    \n",
      "1 | fc2  | Linear | 18    \n",
      "--------------------------------\n",
      "73        Trainable params\n",
      "0         Non-trainable params\n",
      "73        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 67.50it/s, loss=1.1, v_num=2]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 62.78it/s, loss=1.1, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "# 学習に関する一連の流れを実行\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net = Net()\n",
    "trainer = Trainer()\n",
    "\n",
    "trainer.fit(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的な結果は trainer のcallback_metrics に格納される。\n",
    "# テストデータに対する結果を検証する場合は trainer.test() メソッドが用意されており、\n",
    "# 実行すると検証用データセットに対する結果とテスト用データセットに対する結果の両方が確認できる。\n",
    "\n",
    "# テストデータに対する結果を検証する場合は test メソッドが用意されており、\n",
    "# 検証用データセットに対する結果とテスト用データセットに対する結果が格納されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at c:\\Users\\ytchi\\Development\\Python\\work\\lightning_logs\\version_4\\checkpoints\\epoch=298-step=3289.ckpt\n",
      "Loaded model weights from checkpoint at c:\\Users\\ytchi\\Development\\Python\\work\\lightning_logs\\version_4\\checkpoints\\epoch=298-step=3289.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 106.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータに対する処理の実行（test_step と test_end）\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  テストデータに対する結果の確認\n",
    "trainer.callback_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可読性と汎用性を向上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ、検証データ、テストデータのそれぞれに対する処理を\n",
    "# TrainNet、ValidationNet、TestNet のクラスにそれぞれ記述し、\n",
    "# それらを継承した Net に変化のある部分を記述\n",
    "\n",
    "# このように記述を行うと、Net でモデルの構造を記述するだけで良く、可読性が高まる\n",
    "# また、各種のデータに対する処理は毎回同じものを使うことができ、汎用性も高まる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データに対する処理\n",
    "class TrainNet(pl.LightningModule):\n",
    "\n",
    "    # @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(train, self.batch_size, shuffle=True)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        results = {'loss': loss}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データに対する処理\n",
    "class ValidationNet(pl.LightningModule):\n",
    "\n",
    "    # @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(val, self.batch_size)\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        acc = torch.sum(t == y_label) * 1.0 / len(t)\n",
    "        results = {'val_loss': loss, 'val_acc': acc}\n",
    "        return results\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        results = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータに対する処理\n",
    "class TestNet(pl.LightningModule):\n",
    "\n",
    "    # @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(test, self.batch_size)\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, t = batch\n",
    "        y = self.forward(x)\n",
    "        loss = self.lossfun(y, t)\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        acc = torch.sum(t == y_label) * 1.0 / len(t)\n",
    "        results = {'test_loss': loss, 'test_acc': acc}\n",
    "        return results\n",
    "\n",
    "    def test_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        results = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ、検証データ、テストデータへの処理を継承したクラス\n",
    "class Net(TrainNet, ValidationNet, TestNet):\n",
    "    \n",
    "    def __init__(self, input_size=10, hidden_size=5, output_size=3, batch_size=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def lossfun(self, y, t):\n",
    "        return F.cross_entropy(y, t)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc1  | Linear | 55    \n",
      "1 | fc2  | Linear | 18    \n",
      "--------------------------------\n",
      "73        Trainable params\n",
      "0         Non-trainable params\n",
      "73        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138:  20%|██        | 3/15 [11:14<44:57, 224.83s/it, loss=1.1, v_num=1]  \n",
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 76.49it/s, loss=1.1, v_num=3]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 71.47it/s, loss=1.1, v_num=3]\n"
     ]
    }
   ],
   "source": [
    "# 学習に関する一連の流れを実行\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net = Net()\n",
    "trainer = Trainer()\n",
    "\n",
    "trainer.fit(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測精度向上させるテクニック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチノーマリゼーション (Batch Normalization)\n",
    "# ミニバッチごとに平均 μ と 標準偏差 σ を求め、\n",
    "# 平均 β、標準偏差 α となるように変換を行う。\n",
    "# 必ずしも平均 0、標準偏差 1 が良いとは限らないため、\n",
    "# 標準化した後に少し値を変換させることで完全に分布を制限してしまうことを避けている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実装としては、各バッチ毎に平均 μ と標準偏差 σ を定めて標準化を行うという簡単な手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ、検証データ、テストデータへの処理を継承したクラス\n",
    "class Net(TrainNet, ValidationNet, TestNet):\n",
    "    \n",
    "    def __init__(self, input_size=10, hidden_size=5, output_size=3, batch_size=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.bn = nn.BatchNorm1d(input_size) # 追加\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x) # 追加\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def lossfun(self, y, t):\n",
    "        return F.cross_entropy(y, t)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type        | Params\n",
      "-------------------------------------\n",
      "0 | fc1  | Linear      | 55    \n",
      "1 | fc2  | Linear      | 18    \n",
      "2 | bn   | BatchNorm1d | 20    \n",
      "-------------------------------------\n",
      "93        Trainable params\n",
      "0         Non-trainable params\n",
      "93        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 92.62it/s, loss=0.0283, v_num=5] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 15/15 [00:00<00:00, 86.43it/s, loss=0.0283, v_num=5]\n"
     ]
    }
   ],
   "source": [
    "# 学習に関する一連の流れを実行\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net = Net()\n",
    "trainer = Trainer()\n",
    "\n",
    "trainer.fit(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at c:\\Users\\ytchi\\Development\\Python\\work\\lightning_logs\\version_5\\checkpoints\\epoch=999-step=11000.ckpt\n",
      "Loaded model weights from checkpoint at c:\\Users\\ytchi\\Development\\Python\\work\\lightning_logs\\version_5\\checkpoints\\epoch=999-step=11000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 168.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータに対する処理の実行（test_step と test_end）\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果の確認\n",
    "trainer.callback_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルの保存から推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-0.6206, -0.1084,  0.8248, -1.4392, -0.9782,  1.6249,  0.5771,  0.2370,\n",
       "                        0.3248, -1.5282],\n",
       "                      [-1.0523, -0.8148, -0.0732,  1.1580,  0.9905, -1.0875, -0.7037,  0.1645,\n",
       "                        1.4862, -0.0513],\n",
       "                      [-1.1830, -0.1483,  0.5771,  0.0274,  0.0606, -0.3696, -0.4341, -0.1305,\n",
       "                       -0.5154,  0.4619],\n",
       "                      [-0.3722,  0.7309,  0.1979, -0.0273,  0.5360, -1.3404, -0.4401,  1.4830,\n",
       "                        0.2171, -0.4927],\n",
       "                      [ 0.5829, -0.4404,  0.1842,  0.3183,  0.0820, -1.2322,  0.1969, -0.0223,\n",
       "                        0.1850, -0.4095]])),\n",
       "             ('fc1.bias', tensor([0.2524, 0.4649, 0.3014, 0.2918, 0.8056])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.8988,  0.0971, -1.4651, -0.3207, -1.7956],\n",
       "                      [ 1.1254,  1.0925,  0.4449, -0.5528,  1.1171],\n",
       "                      [-0.3440, -0.9093,  0.5122,  0.9761,  1.1225]])),\n",
       "             ('fc2.bias', tensor([ 4.5857, -2.4222, -2.4962])),\n",
       "             ('bn.weight',\n",
       "              tensor([1.8223, 1.2178, 1.0802, 1.6484, 1.3155, 2.3578, 0.9015, 1.5765, 1.6170,\n",
       "                      1.8735])),\n",
       "             ('bn.bias',\n",
       "              tensor([ 0.5247,  0.1926,  0.0690, -0.0361,  0.3045,  0.3016, -0.0937,  0.5890,\n",
       "                      -0.1788,  0.1198])),\n",
       "             ('bn.running_mean',\n",
       "              tensor([1.2970e+01, 2.3692e+00, 1.9622e+01, 9.8141e+01, 2.2580e+00, 1.9030e+00,\n",
       "                      3.7490e-01, 5.1721e+00, 9.2868e-01, 7.4384e+02])),\n",
       "             ('bn.running_var',\n",
       "              tensor([6.0380e-01, 7.5297e-02, 1.1304e+01, 1.6477e+02, 3.8737e-01, 9.5450e-01,\n",
       "                      1.8456e-02, 5.9957e+00, 4.3691e-02, 9.0658e+04])),\n",
       "             ('bn.num_batches_tracked', tensor(11000))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの重み\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルを保存\n",
    "torch.save(net.state_dict(), 'wine.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルを使用した推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルは単にファイルをロードするだけでなく、\n",
    "# モデルの構造を明示しておき、そのモデルに対して、\n",
    "# パラメータの値を当てはめながらロードしていくことになる\n",
    "# 成功すれば <All keys matched successfully> とでるが\n",
    "# パラメータ数などが合わなければ、失敗する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('wine.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測値の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5857, -2.4222, -2.4962], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今回は新しいデータが無いので学習で使用したデータセットのいちばん最初のサンプルに対する予測値を計算\n",
    "# 予測値の計算\n",
    "y = net(x)[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測ラベル\n",
    "torch.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 目的変数\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5da9aad921784b8644505a50d90de01e1bbce0d7772509339b5714d1cab40d5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
